<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="NeRDF">
  <meta name="keywords" content="Novel View Synthesis, Neural Radiance Field">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Efficient View Synthesis with Neural Radiance Distribution Field</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://gaplab.cuhk.edu.cn">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Efficient View Synthesis with Neural Radiance Distribution Field</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=zh-TW&user=x5gpN0sAAAAJ">Yushuang Wu</a><sup>1,2*</sup>, &nbsp</span>
              <span class="author-block">
                <a href="https://pableeto.netlify.app">Xiao Li</a><sup>3#</sup>, &nbsp</span>
              <span class="author-block">
                <a href="https://jingluw.github.io/">Jinglu Wang</a><sup>3</sup>, &nbsp</span>
              <span class="author-block">
                <a href="https://gaplab.cuhk.edu.cn">Xiaoguang Han</a><sup>2,1#</sup>, &nbsp</span>
              <span class="author-block">
                <a href="https://sse.cuhk.edu.cn/en/faculty/cuishuguang">Shuguang Cui</a><sup>2,1</sup>, &nbsp</span>
              <span class="author-block">
                <a href="https://www.microsoft.com/en-us/research/people/yanlu/">Yan Lu</a><sup>3</sup></span>
            </div>
            <h1 style="font-size:23px;font-weight:bold">ICCV 2023</h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>FNii,CUHKSZ, &nbsp</span>
              <span class="author-block"><sup>2</sup>SSE,CUHKSZ, &nbsp</span>
              <span class="author-block"><sup>3</sup>Microsoft Research Asia</span> </br>
              <span class="content has-text-centered"><font size="2">*This work was done when Yushuang Wu was an intern at MSRA.</font></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2304.10179.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2304.10179" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/yushuang-wu/NeRDF"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div align="center"> <img src="figures/pipeline.png" width="900px"> </div>
        <div class="content has-text-centered">
          The overview of our Neural Radiance Distribution Field (NeRDF) and the comparison of (a) NeRF, (b) NeLF, and (c) NeRDF. NeRF requires hundreds of network forwarding per ray to predict the volume density and color, and output the pixel RGB via volume rendering. NeLF takes only one single forwarding per ray to predict the pixel RGB but strongly depends on a much larger network. Our NeRDF absorbs both advantages that takes only one single forwarding per ray as NeLF with only a small network as NeRF. The key idea is to directly predict the radiance distribution from the ray input.
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            Recent work on Neural Radiance Fields (NeRF) has demonstrated significant advances in high-quality view synthesis. A major limitation of NeRF is its low rendering efficiency due to the need for multiple network forwardings to render a single pixel. Existing methods to improve NeRF either reduce the number of required samples or optimize the implementation to accelerate the network forwarding. Despite these efforts, the problem of multiple sampling persists due to the intrinsic representation of radiance fields. In contrast, Neural Light Fields (NeLF) reduce the computation cost of NeRF by querying only one single network forwarding per pixel. To achieve a close visual quality to NeRF, existing NeLF methods require significantly larger network capacities which limits their rendering efficiency in practice. In this work, we propose a new representation called Neural Radiance Distribution Field (NeRDF) that targets efficient view synthesis in real-time. Specifically, we use a small network similar to NeRF while preserving the rendering speed with a single network forwarding per pixel as in NeLF. The key is to model the radiance distribution along each ray with frequency basis and predict frequency weights using the network. Pixel values are then computed via volume rendering on radiance distributions. Experiments show that our proposed method offers a better trade-off among speed, quality, and network size than existing methods: we achieve a ~254x speed-up over NeRF with similar network size, with only a marginal performance decline.
          </div>
        </div>
      </div>

    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          
          <div class="column is-full-width">
            <!-- Results -->
            <h2 class="title is-3">Results</h2>
            <div align="center"> <img src="figures/psnr_vs_fps.png" width="900px"> </div>
            <div class="content has-text-centered">
            Trade-off curves between PSNR and FPS of ours, NeLF-based methods (left), and NeRF-based methods (right), on Fern of the LLFF dataset.
            </br>
            </br>
            </br>
            <div align="center"> <img src="figures/vis_result.png" width="900px"> </div>
            <div class="content has-text-centered">
            Qualitative comparisons. Compared with a 16-layer R2L (R2L-16) that produces much blur, ours has a high quality.
          </div>
        </div>
      </div>
    </div>
  </section>
    
    
  

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{wu2023nerdf,
  title={Efficient View Synthesis with Neural Radiance Distribution Field},
  author={Yushuang, Wu and Xiao, Li and Jinglu, Wang and Xiaoguang, Han and Shuguang, Cui and Yan, Lu},
  booktitle={The IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2023}
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div align="center" class="container">
      <div class="columns is-centered">
        <div class="content">
          This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
        </div>
      </div>
    </div>
  </footer>

</body>

</html>

